{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "985bf4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST, FashionMNIST\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "73581175",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = FashionMNIST(root='./data', train=False, download=True, transform=transform) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e8e6c933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset FashionMNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: ./data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.5,), std=(0.5,))\n",
       "            ),\n",
       " Dataset FashionMNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: ./data\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.5,), std=(0.5,))\n",
       "            ))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "08996052",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9c0be33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 938, Test: 157\n",
      "Per batch of Train_X Shape torch.Size([64, 1, 28, 28])\n",
      "Per batch of Train_y Shape torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=64\n",
    "train_loader=DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "test_loader=DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "print(f\"Train: {len(train_loader)}, Test: {len(test_loader)}\")\n",
    "print(f\"Per batch of Train_X Shape {next(iter(train_loader))[0].shape}\")\n",
    "print(f\"Per batch of Train_y Shape {next(iter(train_loader))[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0a4c2ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "plt.figure(figsize=(5, 8))\n",
    "for i in range(4):\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    img = images[i].squeeze().numpy() \n",
    "    plt.imshow(img, cmap='gray', vmin=-1, vmax=1)\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b8f9a60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_positional_embedding(time_steps, dimension:int):\n",
    "    # embedding=torch.zeros(dimension)\n",
    "    \n",
    "    # for i in range(dimension):\n",
    "    #     k=i - i%2\n",
    "    #     if i%2==0:\n",
    "    #         embedding[i]=torch.sin(time_step/(10000**(k/dimension)))\n",
    "    #     else:\n",
    "    #         embedding[i]=torch.cos(time_step/(10000**(k/dimension)))\n",
    "\n",
    "    # return embedding\n",
    "    # idx=torch.arange(dimension)\n",
    "    # k=idx -(idx%2)\n",
    "    # angle=time_step/(10000**(k/dimension))\n",
    "    # embedding[0::2]=torch.sin(angle[0::2])\n",
    "    # embedding[1::2]=torch.cos(angle[1::2])\n",
    "\n",
    "    # return embedding\n",
    "    half = dimension // 2\n",
    "\n",
    "    freqs_w = torch.exp(\n",
    "        -torch.log(torch.tensor(10000.0)) * (torch.arange(half, dtype=torch.float32) / half)\n",
    "    ).to(time_steps.device)\n",
    "    args = time_steps.float().unsqueeze(1) * freqs_w.unsqueeze(0)\n",
    "    emb = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)\n",
    "    if dimension % 2 == 1:\n",
    "        emb = torch.cat([emb, torch.zeros(time_steps.shape[0], 1, device=time_steps.device)], dim=-1)\n",
    "\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dc0c8370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.tensor([1,2,3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "33fa1f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 128])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_positional_embedding(a,128).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ceb02f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "89e85ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, out_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(out_dim, out_dim)\n",
    "        )\n",
    "    def forward(self, x):  # x: [B, in_dim]\n",
    "        return self.net(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "42849715",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self,dimension=128, in_channels=1,out_channels=1): # can be 64 too, rule of thumb 2*base_channels(32 here)\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dimension=dimension\n",
    "\n",
    "        self.act=nn.SiLU(inplace=True)\n",
    "        # self.pool=nn.MaxPool2d(2)\n",
    "\n",
    "        self.mlp1=MLP(in_dim=dimension,out_dim=32)\n",
    "        self.enc1 = nn.Conv2d(in_channels, 32, 3, padding=1)\n",
    "            \n",
    "        self.pool1 = nn.MaxPool2d(2) # 14 x 14\n",
    "\n",
    "        self.mlp2=MLP(in_dim=dimension,out_dim=64)\n",
    "        self.enc2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "            \n",
    "        self.pool2 = nn.MaxPool2d(2) # 7 x 7\n",
    "\n",
    "        self.mlp3=MLP(in_dim=dimension,out_dim=128)\n",
    "        self.enc3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "            \n",
    "        self.pool3 = nn.MaxPool2d(2) # 3 x 3\n",
    "\n",
    "        self.mlp4=MLP(in_dim=dimension,out_dim=256)\n",
    "        self.enc4 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "            \n",
    "        self.pool4 = nn.MaxPool2d(2) # 1 x 1\n",
    "\n",
    "        self.mlp5=MLP(in_dim=dimension,out_dim=512)\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 3, padding=1),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            # nn.SiLU(inplace=True)\n",
    "        )  # 1 x 1\n",
    "\n",
    "        self.mlp6=MLP(in_dim=dimension,out_dim=256)\n",
    "        self.up4=nn.ConvTranspose2d(in_channels=512,out_channels=256, kernel_size=3, stride=3) # 3 x 3\n",
    "        self.dec4 = nn.Conv2d(512, 256, 3, padding=1)\n",
    "            \n",
    "\n",
    "        self.mlp7=MLP(in_dim=dimension,out_dim=128)\n",
    "        self.up3=nn.ConvTranspose2d(in_channels=256,out_channels=128, kernel_size=3, stride=2) # 7 x 7\n",
    "        self.dec3 = nn.Conv2d(256, 128, 3, padding=1)\n",
    "            \n",
    "\n",
    "        self.mlp8=MLP(in_dim=dimension,out_dim=64)\n",
    "        self.up2=nn.ConvTranspose2d(in_channels=128,out_channels=64, kernel_size=2, stride=2) # 14 x 14\n",
    "        self.dec2 = nn.Conv2d(128, 64, 3, padding=1)\n",
    "            \n",
    "\n",
    "        self.mlp9=MLP(in_dim=dimension,out_dim=32)\n",
    "        self.up1=nn.ConvTranspose2d(in_channels=64,out_channels=32, kernel_size=2, stride=2) # 28 x 28\n",
    "        self.dec1 = nn.Conv2d(64, 32, 3, padding=1)\n",
    "\n",
    "        self.final_conv = nn.Conv2d(32, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self,x,time_steps): \n",
    "        # x: [B, in_ch, H, W], time_steps: [B] \n",
    "        B = x.shape[0]\n",
    "        uemb = make_positional_embedding(time_steps, self.dimension).to(x.device)\n",
    "\n",
    "        # Encoder (conv -> add pos -> act)\n",
    "        h1 = self.enc1(x)\n",
    "        t1 = self.mlp1(uemb).view(B, 32, 1, 1)\n",
    "        a1 = self.act(h1 + t1)\n",
    "        p1 = self.pool1(a1)\n",
    "\n",
    "        h2 = self.enc2(p1)\n",
    "        t2 = self.mlp2(uemb).view(B, 64, 1, 1)\n",
    "        a2 = self.act(h2 + t2)\n",
    "        p2 = self.pool2(a2)\n",
    "\n",
    "        h3 = self.enc3(p2)\n",
    "        t3 = self.mlp3(uemb).view(B, 128, 1, 1)\n",
    "        a3 = self.act(h3 + t3)\n",
    "        p3 = self.pool3(a3)\n",
    "\n",
    "        h4 = self.enc4(p3)\n",
    "        t4 = self.mlp4(uemb).view(B, 256, 1, 1)\n",
    "        a4 = self.act(h4 + t4)\n",
    "        p4 = self.pool4(a4)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(p4)\n",
    "        t5 = self.mlp5(uemb).view(B, 512, 1, 1)\n",
    "        a5 = self.act(b + t5)\n",
    "\n",
    "        # Decoder: skip connect -> conv -> add pos -> activation \n",
    "        u6 = self.up4(a5)                 # (B,256,3,3)\n",
    "        x6 = torch.cat([u6, a4], dim=1)   # (B,512,3,3)\n",
    "        d6 = self.dec4(x6)          \n",
    "        t6 = self.mlp6(uemb).view(B, 256, 1, 1)\n",
    "        a6 = self.act(d6 + t6)\n",
    "\n",
    "        u7 = self.up3(a6)\n",
    "        x7 = torch.cat([u7, a3], dim=1)\n",
    "        d7 = self.dec3(x7)\n",
    "        t7 = self.mlp7(uemb).view(B, 128, 1, 1)\n",
    "        a7 = self.act(d7 + t7)\n",
    "\n",
    "        u8 = self.up2(a7)\n",
    "        x8 = torch.cat([u8, a2], dim=1)\n",
    "        d8 = self.dec2(x8)\n",
    "        t8 = self.mlp8(uemb).view(B, 64, 1, 1)\n",
    "        a8 = self.act(d8 + t8)\n",
    "\n",
    "        u9 = self.up1(a8)\n",
    "        x9 = torch.cat([u9, a1], dim=1)\n",
    "        d9 = self.dec1(x9)\n",
    "        t9 = self.mlp9(uemb).view(B, 32, 1, 1)\n",
    "        a9 = self.act(d9 + t9)\n",
    "\n",
    "        out = self.final_conv(a9)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2ae5393d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([4, 1, 28, 28])\n",
      "Timestep shape: torch.Size([4])\n",
      "Output shape: torch.Size([4, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "model = UNet(\n",
    "    dimension=128,\n",
    "    in_channels=1,\n",
    "    out_channels=1\n",
    ")\n",
    "\n",
    "# model = model.cuda()  # optional\n",
    "\n",
    "\n",
    "# --- Create fake input batch ---\n",
    "B = 4\n",
    "x = torch.randn(B, 1, 28, 28)   # input\n",
    "t = torch.randint(0, 1000, (B,))  # timesteps\n",
    "\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Timestep shape:\", t.shape)\n",
    "\n",
    "# --- Run forward pass ---\n",
    "out = model(x, t)\n",
    "\n",
    "print(\"Output shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7c83bd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T=1000\n",
    "# betas=torch.linspace(1e-4,0.02,T)\n",
    "# alphas=1-betas\n",
    "# alpha_bars=torch.cumprod(alphas,dim=0)\n",
    "# sqrt_alpha_bars=torch.sqrt(alpha_bars)\n",
    "# sqrt_om_alpha_bars=torch.sqrt(1-alpha_bars) # om--one minus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0c295a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def q_sample(x0,t,eps):\n",
    "#     # t: [B] ints in [0..T-1]\n",
    "#     sqrt_alpha_t_bar=sqrt_alpha_bars[t-1].view(-1,1,1,1)\n",
    "#     om_sqrt_alpha_t_bar=sqrt_om_alpha_bars[t-1].view(-1,1,1,1)\n",
    "#     xt=sqrt_alpha_t_bar*x0 + om_sqrt_alpha_t_bar*eps\n",
    "\n",
    "#     return xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6e3347c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_beta_schedule(T, s=0.008):\n",
    "    steps = T\n",
    "    timesteps = torch.arange(steps + 1, dtype=torch.float64)\n",
    "    alphas_cumprod = torch.cos(((timesteps / steps) + s) / (1 + s) * math.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = []\n",
    "    for t in range(1, steps + 1):\n",
    "        beta = min(1 - (alphas_cumprod[t] / alphas_cumprod[t - 1]), 0.999)\n",
    "        betas.append(beta)\n",
    "    return torch.tensor(betas, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0cd89ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMA:\n",
    "    def __init__(self, model: nn.Module, decay=0.9999):\n",
    "        self.decay = decay\n",
    "        self.shadow = {}\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "    def update(self, model):\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name].mul_(self.decay).add_(param.data, alpha=1.0 - self.decay)\n",
    "    def apply_shadow(self, model):\n",
    "        self.backup = {}\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.backup[name] = param.data.clone()\n",
    "                param.data.copy_(self.shadow[name])\n",
    "    def restore(self, model):\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                param.data.copy_(self.backup[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a7379438",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self,T=1000,in_channels=1,out_channels=1,beta_schedule='linear'):\n",
    "        super().__init__()\n",
    "        self.unet=UNet(dimension=128,in_channels=in_channels,out_channels=out_channels)\n",
    "\n",
    "        self.T=T\n",
    "        if beta_schedule == 'cosine':\n",
    "            self.betas = cosine_beta_schedule(self.T)\n",
    "        else:\n",
    "            self.betas = torch.linspace(1e-4, 0.02, T)\n",
    "        # self.betas=torch.linspace(1e-4,0.02,T)\n",
    "        self.alphas=1.0-self.betas\n",
    "        self.alpha_bars=torch.cumprod(self.alphas,dim=0)\n",
    "        self.sqrt_alpha_bars=torch.sqrt(self.alpha_bars)\n",
    "        self.sqrt_om_alpha_bars=torch.sqrt(1-self.alpha_bars) # om--one minus\n",
    "\n",
    "    def q_sample(self,x0,t,eps):\n",
    "        # x0: [B,C,H,W] ,t: [B] ints in [1..T]\n",
    "        sqrt_alpha_t_bar=self.sqrt_alpha_bars[t-1].view(-1,1,1,1)\n",
    "        om_sqrt_alpha_t_bar=self.sqrt_om_alpha_bars[t-1].view(-1,1,1,1)\n",
    "        xt=sqrt_alpha_t_bar*x0 + om_sqrt_alpha_t_bar*eps\n",
    "\n",
    "        return xt\n",
    "    \n",
    "    def p_mean_variance(self,xt,t):\n",
    "        epsilon_hat=self.unet(xt,t)\n",
    "        alpha_t=self.alphas[t-1].view(-1,1,1,1)\n",
    "        sqrt_om_alpha_t_bar=self.sqrt_om_alpha_bars[t-1].view(-1,1,1,1)\n",
    "        beta_t=self.betas[t-1].view(-1,1,1,1)\n",
    "\n",
    "        mu_theta=(1/torch.sqrt(alpha_t))*(xt-(beta_t/sqrt_om_alpha_t_bar)*epsilon_hat)\n",
    "        var = beta_t # simpler choice\n",
    "        return mu_theta,var,epsilon_hat\n",
    "\n",
    "    def p_sample(self, xt, t):\n",
    "        mu, var, eps_hat = self.p_mean_variance(xt, t)\n",
    "        if (t == 1).all():\n",
    "            return mu\n",
    "        z = torch.randn_like(xt)\n",
    "        sigma = torch.sqrt(var)\n",
    "        return mu + sigma * z\n",
    "\n",
    "    def generate_output(self,shape):\n",
    "        xt=torch.randn(shape)\n",
    "        for t in reversed(torch.arange(1,self.T+1)):\n",
    "            t_batch = torch.full((shape[0],), t, dtype=torch.long)\n",
    "            xt=self.p_sample(xt,t_batch)\n",
    "        return xt\n",
    "\n",
    "\n",
    "    def forward(self,x0,t):\n",
    "        # x0: [B,C,H,W] ,t: [B] \n",
    "        eps=torch.randn_like(x0)  # we need epsilon also of size  [B,C,H,W]\n",
    "        xts=self.q_sample(x0,t,eps) # xts: [B,C,H,W]\n",
    "        eps_pred = self.unet(xts, t)\n",
    "\n",
    "        return eps_pred,eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3a2093a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.full((5,2), 0, dtype=torch.long )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fe5b452f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 4, 3, 2, 1])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reversed(torch.arange(1,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1e8fd15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bdeee3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_model_1=DiffusionModel(T=200,in_channels=1,out_channels=1,beta_schedule='cosine').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "42503cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=nn.MSELoss()\n",
    "optimizer=torch.optim.AdamW(params=diffusion_model_1.parameters(), lr=2e-4 )\n",
    "EPOCHS=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8b97e9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ema=EMA(diffusion_model_1,decay=0.995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cfbb3d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3fe07e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96aed7ff9890432c83af0836cb5f1676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m B\u001b[38;5;241m=\u001b[39mbatch_X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      7\u001b[0m t\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1\u001b[39m,diffusion_model_1\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,(B,))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 9\u001b[0m eps_preds,eps\u001b[38;5;241m=\u001b[39mdiffusion_model_1(batch_X, t) \n\u001b[1;32m     10\u001b[0m loss\u001b[38;5;241m=\u001b[39mloss_fn(eps_preds,eps)\n\u001b[1;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[40], line 51\u001b[0m, in \u001b[0;36mDiffusionModel.forward\u001b[0;34m(self, x0, t)\u001b[0m\n\u001b[1;32m     49\u001b[0m eps\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mrandn_like(x0)  \u001b[38;5;66;03m# we need epsilon also of size  [B,C,H,W]\u001b[39;00m\n\u001b[1;32m     50\u001b[0m xts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_sample(x0,t,eps) \u001b[38;5;66;03m# xts: [B,C,H,W]\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m eps_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munet(xts, t)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m eps_pred,eps\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[12], line 86\u001b[0m, in \u001b[0;36mUNet.forward\u001b[0;34m(self, x, time_steps)\u001b[0m\n\u001b[1;32m     83\u001b[0m p4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool4(a4)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# Bottleneck\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbottleneck(p4)\n\u001b[1;32m     87\u001b[0m t5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp5(uemb)\u001b[38;5;241m.\u001b[39mview(B, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     88\u001b[0m a5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(b \u001b[38;5;241m+\u001b[39m t5)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[1;32m    551\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "diffusion_model_1.train()\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    total_loss_of_epoch=0.0\n",
    "    for batch_X,_ in train_loader:\n",
    "        batch_X=batch_X.to(device)\n",
    "        B=batch_X.shape[0]\n",
    "        t=torch.randint(1,diffusion_model_1.T+1,(B,)).to(device)\n",
    "\n",
    "        eps_preds,eps=diffusion_model_1(batch_X, t) \n",
    "        loss=loss_fn(eps_preds,eps)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(diffusion_model_1.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        ema.update(diffusion_model_1)\n",
    "        total_loss_of_epoch+=loss.item()\n",
    "    \n",
    "    avg_loss=total_loss_of_epoch/len(train_loader)\n",
    "    print(f\"Epoch : {epoch}/{EPOCHS} -- Loss : {avg_loss:.4f}\")\n",
    "    losses.append(avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314b7c12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a0c255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9816c833",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
